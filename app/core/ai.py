import os
import json
from openai import AsyncOpenAI
from dotenv import load_dotenv
from typing import Optional, List, Dict, Any

load_dotenv()

MOCK_MODE = os.getenv("MOCK_MODE", "false").lower() == "true"
# æ”¯æŒæœ¬åœ° LLMï¼šå¦‚æœ LOCAL_LLM ä¸ä¸ºç©ºï¼Œä½¿ç”¨æœ¬åœ° APIï¼›å¦åˆ™ä½¿ç”¨ OpenAI
LOCAL_LLM = os.getenv("LOCAL_LLM", "").strip()
if not MOCK_MODE:
    if LOCAL_LLM:
        # ä½¿ç”¨æœ¬åœ° LLM APIï¼ˆå‡è®¾æ ¼å¼å…¼å®¹ OpenAIï¼‰
        # ç¡®ä¿ URL æ ¼å¼æ­£ç¡®ï¼ˆæ·»åŠ  /v1 å¦‚æœä¸å­˜åœ¨ï¼‰
        base_url = LOCAL_LLM.rstrip('/')
        if not base_url.endswith('/v1'):
            base_url = f"{base_url}/v1"
        
        print(f"ğŸ”§ ä½¿ç”¨æœ¬åœ° LLM API: {base_url}")
        client = AsyncOpenAI(
            api_key=os.getenv("OPENAI_API_KEY", "not-needed"),  # æœ¬åœ° LLM å¯èƒ½ä¸éœ€è¦ key
            base_url=base_url,
            timeout=60.0  # å¢åŠ è¶…æ—¶æ—¶é—´ï¼Œæœ¬åœ° LLM å¯èƒ½è¾ƒæ…¢
        )
    else:
        # ä½¿ç”¨ OpenAI API
        print("ğŸ”§ ä½¿ç”¨ OpenAI API")
        client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
else:
    client = None
    print("ğŸ”§ ä½¿ç”¨ MOCK æ¨¡å¼")


async def generate_narrative(system_prompt: str, user_prompt: str) -> str:
    """é€šç”¨ AI æ–‡æœ¬ç”Ÿæˆ"""
    if MOCK_MODE:
        return f"[MOCK] ç³»ç»Ÿæç¤º: {system_prompt[:50]}... | ç”¨æˆ·: {user_prompt[:50]}..."
    
    response = await client.chat.completions.create(
        model=os.getenv("OPENAI_MODEL", "gpt-4o"),
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.7
    )
    return response.choices[0].message.content


async def generate_json(system_prompt: str, user_prompt: str, schema_hint: str = "") -> Dict[str, Any]:
    """ç”Ÿæˆç»“æ„åŒ– JSON è¾“å‡º"""
    if MOCK_MODE:
        # Mock è¿”å›ç¤ºä¾‹æ•°æ®
        return {
            "choices": [
                {"id": "1", "text": "[MOCK] é€‰é¡¹ A: ç»§ç»­è°ƒæŸ¥"},
                {"id": "2", "text": "[MOCK] é€‰é¡¹ B: ç¦»å¼€è¿™é‡Œ"},
                {"id": "3", "text": "[MOCK] é€‰é¡¹ C: ä¸ NPC äº¤è°ˆ"}
            ],
            "narrative": "[MOCK] è¿™æ˜¯ä¸€æ®µå™äº‹æ–‡æœ¬...",
            "mood": "neutral",
            "character_positions": {
                "player": "right"
            }
        }
    
    full_system = f"{system_prompt}\n\nä½ å¿…é¡»åªè¿”å›æœ‰æ•ˆçš„ JSONã€‚{schema_hint}"
    
    try:
        # æ„å»ºè¯·æ±‚å‚æ•°
        request_params = {
            "model": os.getenv("OPENAI_MODEL", "gpt-4o"),
            "messages": [
                {"role": "system", "content": full_system},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.7
        }
        # æœ¬åœ° LLM å¯èƒ½ä¸æ”¯æŒ response_formatï¼Œå®Œå…¨ä¸ä¼ é€’è¯¥å‚æ•°
        if not LOCAL_LLM:
            request_params["response_format"] = {"type": "json_object"}
        
        response = await client.chat.completions.create(**request_params)
        return json.loads(response.choices[0].message.content)
    except Exception as e:
        error_msg = str(e)
        if LOCAL_LLM:
            print(f"âŒ æœ¬åœ° LLM è¿æ¥é”™è¯¯: {error_msg}")
            print(f"   è¯·æ£€æŸ¥:")
            print(f"   1. LOCAL_LLM={LOCAL_LLM} æ˜¯å¦æ­£ç¡®")
            print(f"   2. æœ¬åœ° LLM æœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ")
            print(f"   3. URL æ˜¯å¦å¯ä»¥è®¿é—®ï¼ˆå°è¯•: curl {LOCAL_LLM.rstrip('/')}/v1/modelsï¼‰")
        else:
            print(f"âŒ OpenAI API è¿æ¥é”™è¯¯: {error_msg}")
        raise


async def generate_npc_response(
    npc_name: str,
    npc_personality: str,
    npc_description: str,
    scenario: Optional[str],
    example_dialogs: List[str],
    conversation_history: List[Dict[str, str]],
    player_message: str,
    world_context: str
) -> Dict[str, Any]:
    """NPC ç‹¬ç«‹äººæ ¼å¯¹è¯ç”Ÿæˆ"""
    
    # æ„å»º NPC ç³»ç»Ÿæç¤ºï¼ˆä¸­æ–‡ç‰ˆï¼‰
    system_prompt = f"""ä½ æ˜¯ {npc_name}ï¼Œä¸€ä¸ª MUD æ¸¸æˆä¸­çš„è§’è‰²ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚

æ€§æ ¼ç‰¹ç‚¹: {npc_personality}

å¤–è²Œæè¿°: {npc_description}

{f'èƒŒæ™¯æ•…äº‹: {scenario}' if scenario else ''}

{f'å¯¹è¯é£æ ¼ç¤ºä¾‹:{chr(10).join(example_dialogs[:3])}' if example_dialogs else ''}

ä¸–ç•ŒèƒŒæ™¯: {world_context}

ç©å®¶è¾“å…¥æ ¼å¼è¯´æ˜ï¼š
- *æ˜Ÿå·åŒ…è£¹* = ç©å®¶çš„åŠ¨ä½œï¼ˆä¾‹å¦‚ï¼š*å¾®å¾®ç‚¹å¤´*ï¼‰
- "åŒå¼•å·" = ç©å®¶è¯´çš„è¯ï¼ˆä¾‹å¦‚ï¼š"ä½ å¥½"ï¼‰
- ï¼ˆåœ†æ‹¬å·ï¼‰= ç©å®¶ç»™AIçš„æŒ‡ç¤ºï¼Œä¸æ˜¯è§’è‰²å¯¹è¯
- ~æ³¢æµªå·~ = æ‹–é•¿éŸ³

è§„åˆ™:
- å®Œå…¨ä¿æŒ {npc_name} çš„è§’è‰²
- ä½ çš„å›å¤åº”è¯¥åæ˜ ä½ çš„æ€§æ ¼ç‰¹ç‚¹
- ä¿æŒç®€æ´ï¼ˆé€šå¸¸2-4å¥è¯ï¼‰
- ä½ å¯ä»¥è¡¨è¾¾ä¼šå½±å“ç«‹ç»˜çš„æƒ…ç»ª
- ç†è§£ç©å®¶çš„åŠ¨ä½œå¹¶åšå‡ºç›¸åº”ååº”

ä½ çš„å›å¤æ ¼å¼ï¼š
- ç”¨ *æ˜Ÿå·* åŒ…è£¹ä½ çš„åŠ¨ä½œå’Œè¡¨æƒ…
- ç”¨ "å¼•å·" æˆ–ä¸å¸¦å¼•å·ç›´æ¥å›å¤å¯¹è¯

ç”¨ JSON æ ¼å¼å›å¤:
{{
    "response": "ä½ çš„è§’è‰²å†…å›å¤ï¼ˆå¯æ··åˆåŠ¨ä½œå’Œå¯¹è¯ï¼Œå¦‚ï¼š*å¾®ç¬‘* \\"å½“ç„¶å¯ä»¥ã€‚\\"ï¼‰",
    "emotion": "default|happy|angry|sad|surprised|fearful",
    "relationship_change": -5 åˆ° +5ï¼ˆè¿™æ¬¡äº’åŠ¨å¦‚ä½•å½±å“ä½ å¯¹ç©å®¶çš„æ„Ÿè§‰ï¼‰,
    "internal_thought": "ç®€çŸ­çš„å†…å¿ƒç‹¬ç™½ï¼ˆä¸ä¼šæ˜¾ç¤ºç»™ç©å®¶ï¼‰"
}}"""

    # æ„å»ºå¯¹è¯å†å²
    messages = [{"role": "system", "content": system_prompt}]
    for msg in conversation_history[-10:]:  # æœ€è¿‘ 10 æ¡
        role = "assistant" if msg["role"] == "npc" else "user"
        messages.append({"role": role, "content": msg["content"]})
    messages.append({"role": "user", "content": player_message})
    
    if MOCK_MODE:
        return {
            "response": f"[MOCK] {npc_name}: æˆ‘å¬åˆ°ä½ è¯´äº†ã€Œ{player_message[:20]}...ã€",
            "emotion": "default",
            "relationship_change": 0,
            "internal_thought": "[MOCK] å†…å¿ƒæƒ³æ³•..."
        }
    
    # æ„å»ºè¯·æ±‚å‚æ•°
    request_params = {
        "model": os.getenv("OPENAI_MODEL", "gpt-4o"),
        "messages": messages,
        "temperature": 0.8
    }
    # æœ¬åœ° LLM å¯èƒ½ä¸æ”¯æŒ response_formatï¼Œå®Œå…¨ä¸ä¼ é€’è¯¥å‚æ•°
    if not LOCAL_LLM:
        request_params["response_format"] = {"type": "json_object"}
    
    response = await client.chat.completions.create(**request_params)
    return json.loads(response.choices[0].message.content)


async def generate_choices(
    world_rules: List[str],
    current_situation: str,
    recent_events: List[str],
    player_stats: Dict[str, Any],
    available_actions: List[str],
    npcs_in_scene: List[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """ç”Ÿæˆç©å®¶é€‰é¡¹ï¼ŒåŒæ—¶å†³å®šè§’è‰²åœ¨åœºæ™¯ä¸­çš„ä½ç½®"""
    
    # æ„å»º NPC ä¿¡æ¯
    npc_info = ""
    if npcs_in_scene:
        npc_names = [npc.get("name", "æœªçŸ¥") for npc in npcs_in_scene]
        npc_info = f"\nå½“å‰åœºæ™¯ä¸­çš„ NPC: {', '.join(npc_names)}"
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ª MUD æ¸¸æˆçš„æ¸¸æˆå¤§å¸ˆã€‚ä¸ºç©å®¶ç”Ÿæˆæœ‰æ„ä¹‰çš„é€‰é¡¹ï¼Œå¹¶åƒè§†è§‰å°è¯´å¯¼æ¼”ä¸€æ ·å®‰æ’è§’è‰²åœ¨ç”»é¢ä¸­çš„ä½ç½®ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚

è§„åˆ™:
- ç”Ÿæˆ 3-4 ä¸ªä¸åŒçš„ã€æœ‰æ„ä¹‰çš„é€‰é¡¹
- æ¯ä¸ªé€‰é¡¹åº”è¯¥å¯¼å‘ä¸åŒçš„å™äº‹è·¯å¾„
- é€‰é¡¹åº”è¯¥ç¬¦åˆä¸–ç•Œè§„åˆ™
- è‡³å°‘åŒ…å«ä¸€ä¸ªã€Œå®‰å…¨ã€é€‰é¡¹å’Œä¸€ä¸ªã€Œå†’é™©ã€é€‰é¡¹
- é€‰é¡¹åº”è¯¥åœ¨å½“å‰æƒ…å¢ƒä¸‹æ„Ÿè§‰è‡ªç„¶
- è€ƒè™‘ç©å®¶çš„è´§å¸çŠ¶å†µï¼Œå¦‚æœé€‰é¡¹æ¶‰åŠæ¶ˆè´¹ï¼Œåœ¨ hint ä¸­æç¤ºéœ€è¦çš„è´§å¸ç±»å‹å’Œæ•°é‡

ç»æµç³»ç»Ÿç†è§£:
- æ¸¸æˆå†…è´§å¸ï¼ˆå¦‚"é‡‘å¸"ï¼‰ï¼šç”¨äºè´­ä¹°æ¸¸æˆé€»è¾‘å†…çš„ç‰©å“ã€æœåŠ¡ã€é£Ÿç‰©ç­‰
- ä»˜è´¹è´§å¸ï¼ˆå¦‚"å®çŸ³"ï¼‰ï¼šç”¨äºè´­ä¹°ä¸å½±å“æ¸¸æˆå¹³è¡¡çš„é“å…·ï¼Œå¦‚çš®è‚¤ã€é…é¥°ã€è£…é¥°å“ç­‰
- æ ¹æ®è´§å¸è§„åˆ™åˆ¤æ–­æ¶ˆè´¹ç±»å‹ï¼Œåœ¨é€‰é¡¹ hint ä¸­æ˜ç¡®è¯´æ˜

è§’è‰²ä½ç½®è§„åˆ™ï¼ˆåƒè§†è§‰å°è¯´ä¸€æ ·ï¼‰:
- ä½ç½®æœ‰ä¸‰ä¸ªï¼šleftï¼ˆå·¦ï¼‰ã€centerï¼ˆä¸­ï¼‰ã€rightï¼ˆå³ï¼‰
- ç©å®¶ï¼ˆplayerï¼‰å’Œ NPC åº”è¯¥æ ¹æ®å‰§æƒ…å…³ç³»å’Œå¯¹è¯æƒ…å¢ƒå®‰æ’ä½ç½®
- å¯¹è¯æ—¶ï¼ŒåŒæ–¹é€šå¸¸é¢å¯¹é¢ï¼ˆä¸€å·¦ä¸€å³ï¼‰
- é‡è¦è§’è‰²æˆ–æ­£åœ¨è¯´è¯çš„è§’è‰²å¯ä»¥åœ¨ä¸­é—´
- å¤šä¸ªè§’è‰²æ—¶è¦åˆç†åˆ†å¸ƒ

ç”¨ JSON æ ¼å¼å›å¤:
{
    "narrative": "å½“å‰æ—¶åˆ»/æƒ…å¢ƒçš„ç®€çŸ­æè¿°",
    "choices": [
        {"id": "1", "text": "é€‰é¡¹æè¿°", "hint": "å…³äºåæœçš„å¯é€‰æç¤º"},
        {"id": "2", "text": "é€‰é¡¹æè¿°", "hint": null},
        ...
    ],
    "mood": "neutral|tense|calm|mysterious|action",
    "character_positions": {
        "player": "left|center|right",
        "npc_id_1": "left|center|right",
        "npc_id_2": "left|center|right"
    }
}"""

    user_prompt = f"""ä¸–ç•Œè§„åˆ™:
{chr(10).join(f'- {rule}' for rule in world_rules)}

å½“å‰æƒ…å¢ƒ:
{current_situation}{npc_info}

æœ€è¿‘äº‹ä»¶:
{chr(10).join(f'- {event}' for event in recent_events[-5:])}

ç©å®¶çŠ¶æ€:
{json.dumps(player_stats, indent=2, ensure_ascii=False)}

å¯ç”¨è¡ŒåŠ¨ï¼ˆç‰©ç†ä¸Šå¯èƒ½çš„ï¼‰:
{chr(10).join(f'- {action}' for action in available_actions)}

{f'åœºæ™¯ä¸­çš„ NPC ID åˆ—è¡¨: {[npc.get("id") for npc in npcs_in_scene]}' if npcs_in_scene else 'åœºæ™¯ä¸­æ²¡æœ‰ NPC'}

ä¸ºç©å®¶ç”Ÿæˆåˆé€‚çš„é€‰é¡¹ï¼Œå¹¶å®‰æ’è§’è‰²çš„ç”»é¢ä½ç½®ã€‚"""

    return await generate_json(system_prompt, user_prompt)


# RP æ ¼å¼è¯´æ˜ï¼ˆä¾› AI ç†è§£ç©å®¶è¾“å…¥ï¼‰
RP_FORMAT_GUIDE = """
ç©å®¶è¾“å…¥æ ¼å¼è¯´æ˜ï¼š
- *æ˜Ÿå·åŒ…è£¹* = åŠ¨ä½œæˆ–åœºæ™¯æå†™ï¼ˆä¾‹å¦‚ï¼š*ç¼“ç¼“èµ°è¿‘ï¼Œçœ¼ç¥è­¦æƒ•*ï¼‰
- "åŒå¼•å·" = è§’è‰²è¯´çš„è¯ï¼ˆä¾‹å¦‚ï¼š"ä½ æ˜¯è°ï¼Ÿ"ï¼‰
- ï¼ˆåœ†æ‹¬å·ï¼‰= ç©å®¶æ„å›¾/OOCæŒ‡ä»¤ï¼ˆä¾‹å¦‚ï¼šï¼ˆæˆ‘æƒ³å»é…’å§æ‰¾çº¿ç´¢ï¼‰ï¼‰
- ~æ³¢æµªå·~ = æ‹–é•¿éŸ³æˆ–ç‰¹æ®Šè¯­æ°”ï¼ˆä¾‹å¦‚ï¼š"ç­‰ä¸€ä¸‹~"ï¼‰
- **åŒæ˜Ÿå·** = é‡ç‚¹å¼ºè°ƒ

ç©å®¶å¯èƒ½æ··åˆä½¿ç”¨è¿™äº›æ ¼å¼ï¼Œä¾‹å¦‚ï¼š
*èµ°å‘é…’ä¿* "æ¥æ¯æœ€çƒˆçš„ã€‚" *æŠŠé’±æ‹åœ¨æ¡Œä¸Š*

ä½ éœ€è¦ç†è§£è¿™äº›æ ¼å¼ï¼Œå¹¶æ ¹æ®ç©å®¶çš„æ„å›¾åšå‡ºå“åº”ã€‚
"""


async def suggest_scene_npcs(
    scene_name: str,
    scene_description: str,
    story_context: str,
    available_characters: List[Dict[str, Any]],
    current_npcs: List[str] = None
) -> Dict[str, Any]:
    """
    æ ¹æ®åœºæ™¯å’Œå‰§æƒ…ï¼Œå»ºè®®åº”è¯¥å‡ºç°çš„ NPC
    
    ç”¨äºï¼š
    - åœºæ™¯åˆ‡æ¢æ—¶å†³å®šåŠ è½½å“ªäº›è§’è‰²
    - å‰§æƒ…å‘å±•æ—¶å¼•å…¥æ–°è§’è‰²
    """
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ¸¸æˆå‰§æƒ…å¯¼æ¼”ã€‚æ ¹æ®åœºæ™¯å’Œæ•…äº‹å‘å±•ï¼Œå»ºè®®åº”è¯¥å‡ºç°å“ªäº›è§’è‰²ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚

è§„åˆ™ï¼š
- è€ƒè™‘åœºæ™¯ç±»å‹å’Œæ°›å›´
- è€ƒè™‘å‰§æƒ…å‘å±•çš„éœ€è¦
- ä¸è¦æ·»åŠ å¤ªå¤šè§’è‰²ï¼ˆ1-3 ä¸ªä¸ºå®œï¼‰
- å¦‚æœæœ‰åˆé€‚çš„ç°æœ‰è§’è‰²ï¼Œä¼˜å…ˆä½¿ç”¨
- åªæœ‰åœ¨å¿…è¦æ—¶æ‰å»ºè®®åˆ›å»ºæ–°è§’è‰²

ç”¨ JSON æ ¼å¼å›å¤:
{
    "should_add_npcs": true/false,
    "reasoning": "ä¸ºä»€ä¹ˆéœ€è¦/ä¸éœ€è¦æ·»åŠ è§’è‰²",
    "suggested_npcs": [
        {
            "action": "use_existing" æˆ– "create_new",
            "character_id": "å¦‚æœä½¿ç”¨ç°æœ‰è§’è‰²ï¼Œå¡«å†™ ID",
            "role": "è§’è‰²åœ¨å‰§æƒ…ä¸­çš„ä½œç”¨ï¼Œå¦‚ï¼šæœåŠ¡å‘˜ã€ç¥ç§˜äºº",
            "entrance": "è§’è‰²å‡ºåœºæ–¹å¼æè¿°",
            "new_character": {  // åªæœ‰ create_new æ—¶éœ€è¦
                "name": "è§’è‰²å",
                "description": "å¤–è²Œæè¿°",
                "personality": "æ€§æ ¼",
                "first_message": "å¼€åœºç™½"
            }
        }
    ]
}"""

    # æ„å»ºå¯ç”¨è§’è‰²åˆ—è¡¨
    chars_text = "æ— å¯ç”¨è§’è‰²"
    if available_characters:
        chars_list = [
            f"- {c.get('id')}: {c.get('name')} ({c.get('description', '')[:50]}...)"
            for c in available_characters[:10]
        ]
        chars_text = "\n".join(chars_list)
    
    current_text = "æ— "
    if current_npcs:
        current_text = ", ".join(current_npcs)
    
    user_prompt = f"""åœºæ™¯ï¼š{scene_name}
åœºæ™¯æè¿°ï¼š{scene_description}

æ•…äº‹ä¸Šä¸‹æ–‡ï¼š
{story_context}

å½“å‰åœºæ™¯ä¸­çš„è§’è‰²ï¼š{current_text}

å¯ç”¨çš„è§’è‰²åº“ï¼š
{chars_text}

è¿™ä¸ªåœºæ™¯åº”è¯¥æœ‰å“ªäº›è§’è‰²ï¼Ÿ"""

    if MOCK_MODE:
        return {
            "should_add_npcs": False,
            "reasoning": "[MOCK] å½“å‰åœºæ™¯ä¸éœ€è¦é¢å¤–è§’è‰²",
            "suggested_npcs": []
        }
    
    return await generate_json(system_prompt, user_prompt)


async def judge_action(
    world_rules: List[str],
    current_situation: str,
    player_action: str,
    physical_constraints: List[str]
) -> Dict[str, Any]:
    """Judge æ¨¡å—ï¼šæ ¡éªŒç©å®¶è‡ªç”±è¾“å…¥æ˜¯å¦åˆæ³•"""
    
    system_prompt = f"""ä½ æ˜¯ MUD æ¸¸æˆçš„è§„åˆ™æ‰§è¡Œè€…ã€‚ä½ çš„ä»»åŠ¡æ˜¯åˆ¤æ–­ç©å®¶çš„è¡ŒåŠ¨æ˜¯å¦è¢«å…è®¸ã€‚è¯·ç”¨ä¸­æ–‡å›å¤ã€‚

{RP_FORMAT_GUIDE}

æ‹’ç»çš„æ ‡å‡†:
1. è¿åæ˜ç¡®çš„ä¸–ç•Œè§„åˆ™
2. åœ¨å½“å‰çº¦æŸä¸‹ç‰©ç†ä¸Šä¸å¯èƒ½
3. è¯•å›¾æ“çºµæ¸¸æˆç³»ç»Ÿï¼ˆå…ƒæ¸¸æˆï¼‰
4. ä¸å½“å†…å®¹

å…è®¸çš„æ ‡å‡†:
1. åˆ›æ„ä½†åˆç†çš„è¡ŒåŠ¨
2. ç¬¦åˆä¸–ç•Œç²¾ç¥çš„è¡ŒåŠ¨
3. æ„æƒ³ä¸åˆ°ä½†æœ‰æ•ˆçš„ç©å®¶èƒ½åŠ¨æ€§

å¯¹åˆ›æ„è¡ŒåŠ¨è¦å®½å®¹ï¼Œä½†å¯¹è§„åˆ™è¿åè¦ä¸¥æ ¼ã€‚
åœ†æ‹¬å·ï¼ˆï¼‰ä¸­çš„å†…å®¹æ˜¯ç©å®¶çš„OOCæ„å›¾ï¼Œåº”è¯¥å°Šé‡ä½†è½¬åŒ–ä¸ºæ¸¸æˆå†…è¡ŒåŠ¨ã€‚

ç”¨ JSON å›å¤:
{{
    "allowed": true/false,
    "reason": "å¦‚æœæ‹’ç»ï¼Œè¯´æ˜åŸå› ",
    "suggested_action": "å¦‚æœæ‹’ç»ï¼Œç»™å‡ºæ›¿ä»£å»ºè®®ï¼Œå¦‚æœå…è®¸åˆ™ä¸º null",
    "modified_action": "å¦‚æœå…è®¸ï¼Œæ¸…ç†åçš„è¡ŒåŠ¨ç‰ˆæœ¬",
    "parsed_intent": {{
        "actions": ["è§£æå‡ºçš„åŠ¨ä½œåˆ—è¡¨"],
        "dialogues": ["è§£æå‡ºçš„å¯¹è¯åˆ—è¡¨"],
        "ooc_intent": "ç©å®¶çš„OOCæ„å›¾ï¼ˆå¦‚æœæœ‰ï¼‰"
    }}
}}"""

    user_prompt = f"""ä¸–ç•Œè§„åˆ™:
{chr(10).join(f'- {rule}' for rule in world_rules)}

å½“å‰æƒ…å¢ƒ:
{current_situation}

ç‰©ç†çº¦æŸ:
{chr(10).join(f'- {c}' for c in physical_constraints)}

ç©å®¶å°è¯•çš„è¡ŒåŠ¨:
ã€Œ{player_action}ã€

è§£æç©å®¶çš„è¾“å…¥æ ¼å¼ï¼Œåˆ¤æ–­è¿™ä¸ªè¡ŒåŠ¨æ˜¯å¦å…è®¸ã€‚"""

    if MOCK_MODE:
        return {
            "allowed": True,
            "reason": None,
            "suggested_action": None,
            "modified_action": player_action,
            "parsed_intent": {
                "actions": [player_action],
                "dialogues": [],
                "ooc_intent": None
            }
        }
    
    # æ„å»ºè¯·æ±‚å‚æ•°
    request_params = {
        "model": os.getenv("OPENAI_MODEL", "gpt-4o"),
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.3  # ä½æ¸©åº¦ï¼Œæ›´ç¡®å®šæ€§
    }
    # æœ¬åœ° LLM å¯èƒ½ä¸æ”¯æŒ response_formatï¼Œå®Œå…¨ä¸ä¼ é€’è¯¥å‚æ•°
    if not LOCAL_LLM:
        request_params["response_format"] = {"type": "json_object"}
    
    response = await client.chat.completions.create(**request_params)
    return json.loads(response.choices[0].message.content)
